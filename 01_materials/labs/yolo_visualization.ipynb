{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Object Detection Algorithm - Step-by-Step Visualization\n",
    "\n",
    "This notebook demonstrates each step of the YOLO (You Only Look Once) object detection algorithm. We'll use a pre-trained YOLOv5 model to visualize:\n",
    "\n",
    "1. **Grid Structure** - How YOLO divides images into detection grids\n",
    "2. **Anchor Boxes** - Predefined box shapes used for detection\n",
    "3. **Raw Predictions** - All initial model outputs before filtering\n",
    "4. **Class Predictions** - What the model thinks each box contains\n",
    "5. **Filtering** - Confidence thresholding and Non-Maximum Suppression\n",
    "6. **Final Results** - Clean, labeled bounding boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Model Loading\n",
    "\n",
    "Run the following magic command first to enable inline plotting:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib for saving figures\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive backend\n",
    "import os\n",
    "os.makedirs('yolo_figures', exist_ok=True)\n",
    "\n",
    "# Counter for figure numbering\n",
    "_fig_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision.ops import nms\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# Helper function to save figures instead of showing\n",
    "def showfig(title=\"figure\"):\n",
    "    global _fig_num\n",
    "    _fig_num += 1\n",
    "    filename = f\"yolo_figures/fig_{_fig_num:02d}_{title.replace(' ', '_')}.png\"\n",
    "    plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "    print(f\"Saved: {filename}\")\n",
    "    plt.close()\n",
    "\n",
    "# Set device (use MPS if available on Mac, then CUDA, otherwise CPU)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(f\"Using device: MPS (Apple Silicon GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using device: CUDA\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(f\"Using device: CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv5s model from PyTorch Hub\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test image and resize to exactly 640x640 to match YOLO's expected input\n",
    "image_path = '/Users/alex/Downloads/food.webp'\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# Resize to exactly 640x640 to avoid scaling issues with YOLO predictions\n",
    "image = image.resize((640, 640), Image.LANCZOS)\n",
    "image_np = np.array(image)\n",
    "\n",
    "# Display original image\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(image_np)\n",
    "plt.title('Test Image (640x640)')\n",
    "plt.axis('off')\n",
    "showfig(\"test_image\")\n",
    "\n",
    "print(f\"Image size: {image.size[0]}x{image.size[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grid Visualization\n",
    "\n",
    "YOLO divides the image into a grid and makes predictions for each cell. YOLOv5 uses three different grid scales:\n",
    "- **80x80 grid** - Detects small objects (uses smaller cell size)\n",
    "- **40x40 grid** - Detects medium objects\n",
    "- **20x20 grid** - Detects large objects (uses larger cell size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image is already 640x640, so no preprocessing needed\n",
    "# This matches what YOLO expects\n",
    "preprocessed_img = image_np\n",
    "\n",
    "print(f\"Using preprocessed image: {preprocessed_img.shape[1]}x{preprocessed_img.shape[0]}\")\n",
    "\n",
    "def visualize_grid(image_np, grid_size, title):\n",
    "    \"\"\"Visualize grid overlaid on image\"\"\"\n",
    "    h, w = image_np.shape[:2]\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    ax.imshow(image_np)\n",
    "    \n",
    "    # Draw grid lines\n",
    "    for i in range(grid_size + 1):\n",
    "        x = (w / grid_size) * i\n",
    "        y = (h / grid_size) * i\n",
    "        ax.axvline(x, color='red', linewidth=0.5, alpha=0.5)\n",
    "        ax.axhline(y, color='red', linewidth=0.5, alpha=0.5)\n",
    "    \n",
    "    ax.set_title(f'{title}\\nGrid Size: {grid_size}x{grid_size} cells')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    showfig(f\"grid_{grid_size}\")\n",
    "\n",
    "# Visualize all three grid scales\n",
    "visualize_grid(preprocessed_img, 80, 'Small Objects Scale')\n",
    "visualize_grid(preprocessed_img, 40, 'Medium Objects Scale')\n",
    "visualize_grid(preprocessed_img, 20, 'Large Objects Scale')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anchor Boxes\n",
    "\n",
    "Each grid cell predicts bounding boxes using **anchor boxes** - predefined box shapes. YOLOv5 uses 3 anchor boxes per scale, optimized for different object shapes. This allows the model to detect objects of various aspect ratios within the same grid cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv5 anchor boxes for different scales (width, height)\n",
    "# These are pre-computed anchor shapes for the three detection heads\n",
    "anchors = {\n",
    "    '80x80': [(10, 13), (16, 30), (33, 23)],  # Small objects scale\n",
    "    '40x40': [(30, 61), (62, 45), (59, 119)], # Medium objects scale  \n",
    "    '20x20': [(116, 90), (156, 198), (373, 326)] # Large objects scale\n",
    "}\n",
    "\n",
    "def visualize_anchors(image_np, grid_size, anchors_list, title):\n",
    "    \"\"\"Visualize anchor boxes centered on a sample grid cell\"\"\"\n",
    "    h, w = image_np.shape[:2]\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    ax.imshow(image_np)\n",
    "    \n",
    "    # Pick a grid cell near the center to visualize\n",
    "    cell_x, cell_y = grid_size // 2, grid_size // 2\n",
    "    cell_center_x = (cell_x + 0.5) * (w / grid_size)\n",
    "    cell_center_y = (cell_y + 0.5) * (h / grid_size)\n",
    "    \n",
    "    # Draw the grid cell boundary\n",
    "    cell_w = w / grid_size\n",
    "    cell_h = h / grid_size\n",
    "    cell_x_pos = cell_x * cell_w\n",
    "    cell_y_pos = cell_y * cell_h\n",
    "    \n",
    "    rect = plt.Rectangle((cell_x_pos, cell_y_pos), cell_w, cell_h, \n",
    "                        linewidth=3, edgecolor='red', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # Draw each anchor box centered on the cell\n",
    "    colors = ['blue', 'green', 'yellow']\n",
    "    for i, (anchor_w, anchor_h) in enumerate(anchors_list):\n",
    "        # Convert anchor size to image coordinates (anchors are normalized)\n",
    "        box_w = (anchor_w / 640.0) * w  # 640 is YOLO's reference size\n",
    "        box_h = (anchor_h / 640.0) * h\n",
    "        \n",
    "        # Draw anchor box centered on the cell\n",
    "        box_x = cell_center_x - box_w / 2\n",
    "        box_y = cell_center_y - box_h / 2\n",
    "        \n",
    "        rect = plt.Rectangle((box_x, box_y), box_w, box_h, \n",
    "                            linewidth=2, edgecolor=colors[i], \n",
    "                            facecolor=colors[i], alpha=0.3, label=f'Anchor {i+1}')\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    ax.set_title(f'{title}\\n3 anchor boxes per grid cell', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    showfig(f\"anchors_{grid_size}\")\n",
    "\n",
    "# Visualize anchors for all three scales\n",
    "visualize_anchors(preprocessed_img, 80, anchors['80x80'], 'Small Objects (80x80 grid)')\n",
    "visualize_anchors(preprocessed_img, 40, anchors['40x40'], 'Medium Objects (40x40 grid)')\n",
    "visualize_anchors(preprocessed_img, 20, anchors['20x20'], 'Large Objects (20x20 grid)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Raw Predictions (Before Filtering)\n",
    "\n",
    "The model produces thousands of raw predictions - one for each anchor box in every grid cell. Before any filtering, we can see ALL predictions the model makes. Notice how densely packed and noisy these predictions are!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model to get ALL predictions with very low thresholds\n",
    "model.conf = 0.01  # Very low confidence threshold\n",
    "model.iou = 1.0    # Disable NMS (set IoU threshold to 1.0)\n",
    "\n",
    "# Run inference to get raw predictions\n",
    "results = model(image_path)\n",
    "raw_predictions = results.xyxy[0].cpu().numpy()\n",
    "\n",
    "print(f\"Total raw predictions: {len(raw_predictions):,}\")\n",
    "\n",
    "# Get class names for color-coding\n",
    "class_names = model.names\n",
    "\n",
    "# Visualize all raw predictions\n",
    "plt.figure(figsize=(14, 14))\n",
    "ax = plt.gca()\n",
    "ax.imshow(preprocessed_img)\n",
    "\n",
    "# Color map for classes\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(class_names)))\n",
    "\n",
    "# Track which classes are used for legend\n",
    "used_classes = set()\n",
    "\n",
    "# Draw all predicted boxes\n",
    "for i, pred in enumerate(raw_predictions):\n",
    "    x1, y1, x2, y2, conf, cls = pred\n",
    "    cls_id = int(cls)\n",
    "    w, h = x2 - x1, y2 - y1\n",
    "    \n",
    "    # Color by predicted class\n",
    "    color = colors[cls_id % len(colors)]\n",
    "    \n",
    "    # Track this class for legend\n",
    "    used_classes.add(cls_id)\n",
    "    \n",
    "    # Line thickness by objectness (confidence)\n",
    "    # Scale from 0.5 to 3 based on confidence (0-1)\n",
    "    linewidth = 0.5 + conf * 2.5\n",
    "    \n",
    "    rect = plt.Rectangle((x1, y1), w, h, linewidth=linewidth, \n",
    "                        edgecolor=color, facecolor='none', alpha=0.6)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "ax.set_title(f'All Raw Predictions\\n' +\n",
    "             'Color: predicted class | Line thickness: objectness', \n",
    "            fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add legend for visible classes\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = []\n",
    "for cls_id in sorted(used_classes):\n",
    "    color = colors[cls_id % len(colors)]\n",
    "    class_name = class_names.get(cls_id, f\"class_{cls_id}\")\n",
    "    legend_elements.append(Patch(facecolor=color, edgecolor='black', label=class_name))\n",
    "\n",
    "ax.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.15, 1), \n",
    "          fontsize=9, framealpha=0.9)\n",
    "\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('yolo_figures/raw_predictions.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names\n",
    "class_names = model.names\n",
    "\n",
    "# Show confidence distribution\n",
    "confidence_scores = raw_predictions[:, 4]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(confidence_scores, bins=50, edgecolor='black')\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.ylabel('Number of Predictions')\n",
    "plt.title('Distribution of Confidence Scores\\n(Before Filtering)')\n",
    "plt.axvline(0.25, color='red', linestyle='--', label='Default threshold (0.25)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('yolo_figures/confidence_cutoff.png')\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Statistics:\")\n",
    "print(f\"  Total predictions: {len(confidence_scores):,}\")\n",
    "print(f\"  Mean confidence: {confidence_scores.mean():.4f}\")\n",
    "print(f\"  Max confidence: {confidence_scores.max():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Class Predictions\n",
    "\n",
    "For each predicted box, YOLO outputs:\n",
    "1. **Objectness score**: Confidence that an object exists (regardless of class)\n",
    "2. **Class probabilities**: A probability distribution over all 80 COCO classes\n",
    "3. **Final confidence**: objectness Ã— max(class_probability)\n",
    "\n",
    "Let's examine the top predictions and their class distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort predictions by confidence and look at top 5\n",
    "sorted_preds = raw_predictions[np.argsort(raw_predictions[:, 4])[::-1]]\n",
    "\n",
    "print(\"Top 5 Predictions (by confidence):\")\n",
    "print(\"=\" * 80)\n",
    "for i, pred in enumerate(sorted_preds[:5]):\n",
    "    x1, y1, x2, y2, conf, cls_id = pred\n",
    "    cls_id = int(cls_id)\n",
    "    class_name = class_names.get(cls_id, f\"class_{cls_id}\")\n",
    "    print(f\"\\n{i+1}. {class_name}\")\n",
    "    print(f\"   Confidence: {conf:.4f}\")\n",
    "    print(f\"   Bounding box: ({x1:.0f}, {y1:.0f}) to ({x2:.0f}, {y2:.0f})\")\n",
    "\n",
    "# Visualize top predictions with labels\n",
    "plt.figure(figsize=(14, 14))\n",
    "ax = plt.gca()\n",
    "ax.imshow(preprocessed_img)\n",
    "\n",
    "# Draw top 5 predictions\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, 5))\n",
    "for i, (pred, color) in enumerate(zip(sorted_preds[:5], colors)):\n",
    "    x1, y1, x2, y2, conf, cls_id = pred\n",
    "    cls_id = int(cls_id)\n",
    "    class_name = class_names.get(cls_id, f\"class_{cls_id}\")\n",
    "    w, h = x2 - x1, y2 - y1\n",
    "    \n",
    "    rect = plt.Rectangle((x1, y1), w, h, linewidth=3, \n",
    "                        edgecolor=color, facecolor='none', alpha=0.8)\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # Add label\n",
    "    label = f'{i+1}. {class_name} ({conf:.3f})'\n",
    "    ax.text(x1, y1-5, label, \n",
    "           bbox=dict(boxstyle='round,pad=0.3', facecolor=color, alpha=0.7),\n",
    "           fontsize=10, fontweight='bold', color='white')\n",
    "\n",
    "ax.set_title('Top 5 Predictions by Confidence Score', fontsize=16, fontweight='bold')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6a. Confidence Filtering\n",
    "\n",
    "The first filtering step removes predictions with low confidence. We apply a threshold (typically 0.25) to keep only confident detections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply confidence thresholding\n",
    "confidence_threshold = 0.25\n",
    "filtered_by_confidence = raw_predictions[raw_predictions[:, 4] >= confidence_threshold]\n",
    "\n",
    "print(f\"Predictions before confidence filtering: {len(raw_predictions):,}\")\n",
    "print(f\"Predictions after confidence filtering (threshold={confidence_threshold}): {len(filtered_by_confidence):,}\")\n",
    "print(f\"Reduction: {len(raw_predictions) - len(filtered_by_confidence):,} predictions removed \"\n",
    "      f\"({100*(1 - len(filtered_by_confidence)/len(raw_predictions)):.1f}%)\")\n",
    "\n",
    "# Visualize comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Before filtering\n",
    "ax1.imshow(preprocessed_img)\n",
    "for pred in raw_predictions[:100]:  # Show first 100\n",
    "    x1, y1, x2, y2 = pred[:4]\n",
    "    w, h = x2 - x1, y2 - y1\n",
    "    rect = plt.Rectangle((x1, y1), w, h, linewidth=1.5, \n",
    "                        edgecolor='cyan', facecolor='none', alpha=0.6)\n",
    "    ax1.add_patch(rect)\n",
    "ax1.set_title(f'Before Confidence Filtering\\n{len(raw_predictions):,} predictions (showing 100)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax1.axis('off')\n",
    "\n",
    "# After filtering\n",
    "ax2.imshow(preprocessed_img)\n",
    "for pred in filtered_by_confidence:\n",
    "    x1, y1, x2, y2 = pred[:4]\n",
    "    w, h = x2 - x1, y2 - y1\n",
    "    rect = plt.Rectangle((x1, y1), w, h, linewidth=2, \n",
    "                        edgecolor='yellow', facecolor='none', alpha=0.7)\n",
    "    ax2.add_patch(rect)\n",
    "ax2.set_title(f'After Confidence Filtering (threshold={confidence_threshold})\\n{len(filtered_by_confidence):,} predictions', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('yolo_figures/confident_boxes.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6b. Non-Maximum Suppression (NMS)\n",
    "\n",
    "NMS removes duplicate detections of the same object by:\n",
    "1. Sorting boxes by confidence\n",
    "2. Keeping the highest-confidence box\n",
    "3. Removing other boxes that overlap significantly (high IoU) with it\n",
    "4. Repeating for remaining boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply NMS to each class separately\n",
    "final_predictions = []\n",
    "\n",
    "unique_classes = np.unique(filtered_by_confidence[:, 5])\n",
    "\n",
    "for cls in unique_classes:\n",
    "    # Get predictions for this class\n",
    "    cls_predictions = filtered_by_confidence[filtered_by_confidence[:, 5] == cls]\n",
    "    \n",
    "    # Convert to tensors for NMS\n",
    "    boxes = torch.from_numpy(cls_predictions[:, :4]).float()\n",
    "    scores = torch.from_numpy(cls_predictions[:, 4]).float()\n",
    "    \n",
    "    # Apply NMS with IoU threshold 0.45\n",
    "    keep_indices = nms(boxes, scores, iou_threshold=0.45)\n",
    "    \n",
    "    # Convert keep_indices to numpy array and get the predictions\n",
    "    keep_indices_np = keep_indices.cpu().numpy()\n",
    "    if len(cls_predictions) > 0 and len(keep_indices_np) > 0:\n",
    "        # Ensure we have a 2D array\n",
    "        kept_preds = cls_predictions[keep_indices_np]\n",
    "        if len(kept_preds.shape) == 1:\n",
    "            kept_preds = kept_preds.reshape(1, -1)\n",
    "        final_predictions.append(kept_preds)\n",
    "\n",
    "# Concatenate all class predictions\n",
    "final_predictions = np.concatenate(final_predictions, axis=0) if final_predictions else np.array([]).reshape(0, 6)\n",
    "\n",
    "print(f\"Predictions before NMS: {len(filtered_by_confidence)}\")\n",
    "print(f\"Predictions after NMS: {len(final_predictions)}\")\n",
    "print(f\"Reduction: {len(filtered_by_confidence) - len(final_predictions)} duplicates removed \"\n",
    "      f\"({100*(1 - len(final_predictions)/len(filtered_by_confidence)):.1f}%)\")\n",
    "\n",
    "# Visualize comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Before NMS\n",
    "ax1.imshow(preprocessed_img)\n",
    "for pred in filtered_by_confidence[:50]:  # Show first 50\n",
    "    x1, y1, x2, y2 = pred[:4]\n",
    "    w, h = x2 - x1, y2 - y1\n",
    "    rect = plt.Rectangle((x1, y1), w, h, linewidth=2, \n",
    "                        edgecolor='yellow', facecolor='none', alpha=0.7)\n",
    "    ax1.add_patch(rect)\n",
    "ax1.set_title(f'Before NMS\\n{len(filtered_by_confidence)} predictions (showing 50)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax1.axis('off')\n",
    "\n",
    "# After NMS\n",
    "ax2.imshow(preprocessed_img)\n",
    "for pred in final_predictions:\n",
    "    x1, y1, x2, y2 = pred[:4]\n",
    "    w, h = x2 - x1, y2 - y1\n",
    "    rect = plt.Rectangle((x1, y1), w, h, linewidth=2, \n",
    "                        edgecolor='green', facecolor='none', alpha=0.7)\n",
    "    ax2.add_patch(rect)\n",
    "ax2.set_title(f'After NMS\\n{len(final_predictions)} final predictions', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('yolo_figures/nms_fig.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Results\n",
    "\n",
    "Here are the final, cleaned detections with class labels and confidence scores:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize final results with labels\n",
    "plt.figure(figsize=(14, 14))\n",
    "ax = plt.gca()\n",
    "ax.imshow(preprocessed_img)\n",
    "\n",
    "# Color-code by class\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(class_names)))\n",
    "\n",
    "for pred in final_predictions:\n",
    "    x1, y1, x2, y2, conf, cls_id = pred\n",
    "    cls_id = int(cls_id)\n",
    "    class_name = class_names.get(cls_id, f\"class_{cls_id}\")\n",
    "    w, h = x2 - x1, y2 - y1\n",
    "    color = colors[cls_id % len(colors)]\n",
    "    \n",
    "    # Draw bounding box\n",
    "    rect = plt.Rectangle((x1, y1), w, h, linewidth=3, \n",
    "                        edgecolor=color, facecolor='none', alpha=0.8)\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # Draw label with confidence\n",
    "    label = f'{class_name}: {conf:.2f}'\n",
    "    ax.text(x1, y1-5, label, \n",
    "           bbox=dict(boxstyle='round,pad=0.3', facecolor=color, alpha=0.6),\n",
    "           fontsize=11, fontweight='bold', color='white')\n",
    "\n",
    "ax.set_title(f'Final Detection Results\\n{len(final_predictions)} objects detected', \n",
    "            fontsize=16, fontweight='bold')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('yolo_figures/final_predictions.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=\" * 80)\n",
    "print(\"YOLO DETECTION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nImage: {image_path}\")\n",
    "print(f\"Original size: {image.size[0]}x{image.size[1]}\")\n",
    "print(f\"Preprocessed size: 640x640\")\n",
    "\n",
    "print(f\"\\nDetection Pipeline:\")\n",
    "print(f\"  1. Raw predictions: {len(raw_predictions):,}\")\n",
    "print(f\"  2. After confidence filtering (threshold=0.25): {len(filtered_by_confidence):,}\")\n",
    "print(f\"  3. After Non-Maximum Suppression (IoU=0.45): {len(final_predictions):,}\")\n",
    "\n",
    "print(f\"\\nReduction Statistics:\")\n",
    "print(f\"  Confidence filtering removed: {len(raw_predictions) - len(filtered_by_confidence):,} \"\n",
    "      f\"predictions ({100*(1 - len(filtered_by_confidence)/len(raw_predictions)):.1f}%)\")\n",
    "print(f\"  NMS removed: {len(filtered_by_confidence) - len(final_predictions):,} \"\n",
    "      f\"duplicates ({100*(1 - len(final_predictions)/len(filtered_by_confidence)):.1f}%)\")\n",
    "print(f\"  Total reduction: {len(raw_predictions) - len(final_predictions):,} \"\n",
    "      f\"predictions ({100*(1 - len(final_predictions)/len(raw_predictions)):.1f}%)\")\n",
    "\n",
    "if len(final_predictions) > 0:\n",
    "    print(f\"\\nDetected Objects:\")\n",
    "    for i, pred in enumerate(final_predictions):\n",
    "        x1, y1, x2, y2, conf, cls_id = pred\n",
    "        cls_id = int(cls_id)\n",
    "        class_name = class_names.get(cls_id, f\"class_{cls_id}\")\n",
    "        print(f\"  {i+1}. {class_name}: confidence={conf:.3f}, \"\n",
    "              f\"bbox=({x1:.0f}, {y1:.0f}, {x2:.0f}, {y2:.0f})\")\n",
    "\n",
    "print(\"\\nKey Takeaways:\")\n",
    "print(\"- YOLO processes the entire image in one forward pass (single-stage detection)\")\n",
    "print(\"- Each grid cell predicts multiple boxes using anchor boxes\")\n",
    "print(\"- Confidence filtering removes low-quality predictions\")\n",
    "print(\"- NMS eliminates duplicate detections of the same object\")\n",
    "print(\"- Final results are clean, labeled bounding boxes\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
