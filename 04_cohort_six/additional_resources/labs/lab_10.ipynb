{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "728897d0f4bd1659",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Denoising Autoencoders\n",
    "\n",
    "In this final lab, we will look at using a denoising autoencoder to remove noise from images. We will use the Fashion MNIST dataset and add noise to the images. We will then train a denoising autoencoder to remove the noise from the images.\n",
    "\n",
    "Fashion MNIST is a dataset of low resolution images of clothes. It is a popular dataset for image classification and is often used as a drop-in replacement for the original MNIST dataset.\n",
    "\n",
    "Let's start by loading the dataset and looking at some examples. You'll note that unlike previous labs, we are not even loading the labels! This is because we are going to use the images as both the input and the output of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(x_train, _), (x_test, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd68a73d64ff439",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import choice\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    ax = axs[i]\n",
    "    ax.imshow(x_train[choice(range(len(x_train)))], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561fc5827ac1df",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Adding Noise\n",
    "\n",
    "Because our model will be trained to remove noise from the images, we need to add noise to the images. We will use a simple method of adding Gaussian noise to the images. We will then clip the values to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7bea4ee7858af5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_noise(x, noise_factor=0.1):\n",
    "    x = x + np.random.normal(loc=0.0, scale=noise_factor, size=x.shape)\n",
    "    return np.clip(x, 0., 1.)\n",
    "\n",
    "x_train_noisy = add_noise(x_train)\n",
    "x_test_noisy = add_noise(x_test)\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(15, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    ax = axs[0, i]\n",
    "    idx = choice(range(len(x_train)))\n",
    "    ax.imshow(x_train[idx], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    ax = axs[1, i]\n",
    "    ax.imshow(x_train_noisy[idx], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d4b02f18687b26",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Building the Model\n",
    "\n",
    "Now, let's build a simple autoencoder. This type of model is comprised of two main parts: the encoder and the decoder. The encoder will compress the input image into a lower dimensional representation, and the decoder will attempt to recreate the original image from this lower dimensional representation.\n",
    "\n",
    "We have completed the encoder for you. It is a simple model that flattens the input image and then passes it through two dense layers. The decoder is your task to complete. It should take the output of the encoder and attempt to recreate the original image.\n",
    "\n",
    "**Note:** we are used to squashing the output of our model to be between 0 and 1, either with softmax or sigmoid depending on the use case. However, this should not apply to the output of our encoder! The encoder is not outputting a probability, but rather a representation of the input. As such, we should use an activation function like `relu` for the dense layers of the encoder. The decoder, however, should use `sigmoid` to squash the output to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70fb2f8e08baebc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "encoder = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu')\n",
    "])\n",
    "\n",
    "decoder = models.Sequential([\n",
    "    # Add layers to accept the output of the encoder and attempt to recreate the original image.\n",
    "    # The layers should be the reverse of the encoder.\n",
    "    layers.Reshape((28, 28))\n",
    "])\n",
    "\n",
    "autoencoder = models.Sequential([\n",
    "    encoder,\n",
    "    decoder\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f148c7b11d6c29",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will use binary cross-entropy as the loss function, as we are treating the model as a simple logistic regression model. We will use the Adam optimizer to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eefea3ac3eebc1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee44f3c2b2c254e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Special callback to visualize the training progress\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "def plot_image(i):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "    axs[0].imshow(x_test[i], cmap='gray')\n",
    "    axs[0].set_title('Original')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(x_test_noisy[i], cmap='gray')\n",
    "    axs[1].set_title('Noisy')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(autoencoder.predict(x_test_noisy[[i]])[0], cmap='gray')\n",
    "    axs[2].set_title('De-noised')\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "class VisualizeCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        plot_image(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759b68cb48d12cf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "autoencoder.fit(\n",
    "    x_train_noisy, x_train,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, monitor='val_loss'),\n",
    "        ModelCheckpoint('autoencoder', save_best_only=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf10d7e3b3bdd8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "\n",
    "autoencoder = models.load_model('autoencoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcead94ef10e294c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluating the Model\n",
    "\n",
    "Now that we have trained the model, let's see how well it can remove noise from the images. Use the `plot_image` method to visualize the original images, the noisy images, and the denoised images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43754e23e52f78",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_image(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19657b2525c71fb8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Using Autoencoders for Dimensionality Reduction\n",
    "\n",
    "During the course, we've looked at standard techniques for dimensionality reduction - PCA and t-SNE. We can also use autoencoders for dimensionality reduction. The output of our encoder is a lower-dimensional representation of the input, which is used by the decoder to recreate that input. As a result, we can use just the encoder to get a low-dimensional representation of our input data.\n",
    "\n",
    "In the code below, modify your encoder and decoder so that the encoder outputs a 2-dimensional representation of the input. For this task, we won't use the noisy images to train, since our priority now is creating an accurate representation of the original images. This time we will also work with the labels, but only to visualize the data in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46c9480ab6e84eb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172c357fd5cd6885",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea33534a283df19",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    # Add layers to compress the input image into a 2-dimensional representation\n",
    "    layers.Dense(2, activation=None)\n",
    "])\n",
    "\n",
    "decoder = models.Sequential([\n",
    "    # Add layers to accept the 2-dimensional representation and attempt to recreate the original image.\n",
    "    layers.Reshape((28, 28))\n",
    "])\n",
    "\n",
    "autoencoder = models.Sequential([\n",
    "    encoder,\n",
    "    decoder\n",
    "])\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4bb033419e5a7d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(\n",
    "    x_train, x_train,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, monitor='val_loss'),\n",
    "        ModelCheckpoint('autoencoder', save_best_only=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0f546b5fb6338",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "autoencoder = models.load_model('autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150649b414194cc8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize reconstruction\n",
    "def plot_reconstruction(i):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    axs[0].imshow(x_test[i], cmap='gray')\n",
    "    axs[0].set_title('Original')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(autoencoder.predict(x_test[[i]])[0], cmap='gray')\n",
    "    axs[1].set_title('Reconstructed')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_reconstruction(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1d447c89553e4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "encoded = encoder.predict(x_test)\n",
    "\n",
    "labels = [\n",
    "    'T-shirt/top',\n",
    "    'Trouser',\n",
    "    'Pullover',\n",
    "    'Dress',\n",
    "    'Coat',\n",
    "    'Sandal',\n",
    "    'Shirt',\n",
    "    'Sneaker',\n",
    "    'Bag',\n",
    "    'Ankle boot'\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(x=encoded[:, 0], y=encoded[:, 1], hue=[labels[i] for i in y_test], palette='tab10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f4c430890e5893",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercises\n",
    "\n",
    "1. In the first part of the lab, we added Gaussian noise to the images. You can add different types of noise - take a look at some of the options available in numpy [here](https://numpy.org/doc/stable/reference/random/) and try adding different types of noise to the images. How does this affect the performance of the autoencoder?\n",
    "\n",
    "2. In the second part of the lab, we used the encoder to create a 2-dimensional representation of the input data. We then visualized this representation using a scatter plot. You can also use 3 dimensions instead of 2. How does this affect the reconstruction error? Use the code below to visualize 3D data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37273e9836767b41",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_3d_reconstruction(i):\n",
    "    \"\"\"This code assumes that encoded is 3-dimensional.\"\"\"\n",
    "    fig = px.scatter_3d(\n",
    "        x=encoded[:, 0], y=encoded[:, 1], z=encoded[:, 2],\n",
    "        color=[labels[i] for i in y_test]\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532bc7bc4e10e56",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_3d_reconstruction(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
